{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75e80aa5",
   "metadata": {},
   "source": [
    "# Part 3: ECG Analysis\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this part, you'll work with the MIT-BIH Arrhythmia Database to build a model for heartbeat classification using a simple neural network architecture. This will help you understand how to apply neural networks to time series data in healthcare.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Load and preprocess ECG time series data\n",
    "- Implement a simple neural network for sequence classification\n",
    "- Train and evaluate the model\n",
    "- Interpret results in a clinical context\n",
    "\n",
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9f8cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install -r requirements.txt\n",
    "%pip install wfdb  # For reading MIT-BIH format\n",
    "\n",
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import wfdb\n",
    "from scipy import signal\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure matplotlib for better visualization\n",
    "plt.style.use('seaborn')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Create directories\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('results/part_3', exist_ok=True)\n",
    "os.makedirs('logs', exist_ok=True)\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# Download MIT-BIH dataset\n",
    "data_dir = 'data/mitdb'\n",
    "if not os.path.exists(data_dir):\n",
    "    print(\"Downloading MIT-BIH Arrhythmia Database...\")\n",
    "    url = \"https://www.physionet.org/static/published-projects/mitdb/mit-bih-arrhythmia-database-1.0.0.zip\"\n",
    "    zip_path = 'data/mitdb.zip'\n",
    "    \n",
    "    # Download dataset\n",
    "    urllib.request.urlretrieve(url, zip_path)\n",
    "    \n",
    "    # Extract dataset\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall('data')\n",
    "    \n",
    "    # Clean up\n",
    "    os.remove(zip_path)\n",
    "    print(\"Dataset downloaded and extracted successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbad9e3a",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc51ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ECG data\n",
    "record_path = 'data/mitdb/100'  # Example record\n",
    "record = wfdb.rdrecord(record_path)\n",
    "signals = record.p_signal\n",
    "\n",
    "# Read annotations\n",
    "ann = wfdb.rdann(record_path, 'atr')\n",
    "annotations = ann.symbol\n",
    "\n",
    "# Print data information\n",
    "print(f\"Signal shape: {signals.shape}\")\n",
    "print(f\"Number of annotations: {len(annotations)}\")\n",
    "print(f\"Unique beat types: {np.unique(annotations)}\")\n",
    "\n",
    "# Plot sample ECG segment\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(signals[:1000, 0])\n",
    "plt.title('Sample ECG Segment')\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41618d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess ECG data\n",
    "window_size = 180\n",
    "\n",
    "# Normalize signals\n",
    "signals = (signals - np.mean(signals)) / np.std(signals)\n",
    "\n",
    "# Extract beats\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i, ann in enumerate(annotations):\n",
    "    if ann in ['N', 'L', 'R', 'A', 'V']:  # Normal and abnormal beats\n",
    "        # Get window around beat\n",
    "        start = max(0, i - window_size//2)\n",
    "        end = min(len(signals), i + window_size//2)\n",
    "        \n",
    "        # Pad if necessary\n",
    "        if start == 0:\n",
    "            pad_left = window_size//2 - i\n",
    "            segment = np.pad(signals[start:end], ((pad_left, 0), (0, 0)))\n",
    "        elif end == len(signals):\n",
    "            pad_right = window_size//2 - (len(signals) - i)\n",
    "            segment = np.pad(signals[start:end], ((0, pad_right), (0, 0)))\n",
    "        else:\n",
    "            segment = signals[start:end]\n",
    "        \n",
    "        X.append(segment)\n",
    "        \n",
    "        # Convert annotation to label\n",
    "        if ann == 'N':\n",
    "            y.append(0)  # Normal\n",
    "        else:\n",
    "            y.append(1)  # Abnormal\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(f\"Data shape: {X.shape}\")\n",
    "print(f\"Label distribution: {np.bincount(y)}\")\n",
    "\n",
    "# Plot sample beats\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.plot(X[i, :, 0])\n",
    "    plt.title(f'Beat Type: {\"Normal\" if y[i] == 0 else \"Abnormal\"}')\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85d9093",
   "metadata": {},
   "source": [
    "## 2. Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0147fb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create simple neural network\n",
    "def create_simple_nn(input_shape):\n",
    "    \"\"\"\n",
    "    Create a simple neural network for ECG classification.\n",
    "    \n",
    "    Requirements:\n",
    "    - Must use at least 2 dense layers\n",
    "    - Must include dropout layers\n",
    "    - Must use binary crossentropy loss\n",
    "    - Must include AUC metric\n",
    "    \n",
    "    Goals:\n",
    "    - Achieve > 75% accuracy on test set\n",
    "    - Achieve AUC > 0.80\n",
    "    - Achieve F1-score > 0.70\n",
    "    - Minimize overfitting using dropout\n",
    "    - Train efficiently with appropriate batch size\n",
    "    \n",
    "    Args:\n",
    "        input_shape: Shape of input data (should be (180, 2) for ECG windows)\n",
    "    \n",
    "    Returns:\n",
    "        Compiled Keras model\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential([...])\n",
    "    \n",
    "    model.compile(...)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create and compile model\n",
    "model = create_simple_nn(input_shape=(180, 2))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e87b3c2",
   "metadata": {},
   "source": [
    "## 3. Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3f3a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=3\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        'models/ecg_classifier.keras',\n",
    "        save_best_only=True\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Plot training curves\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot accuracy\n",
    "ax1.plot(history.history['accuracy'], label='Training')\n",
    "ax1.plot(history.history['val_accuracy'], label='Validation')\n",
    "ax1.set_title('Model Accuracy')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot loss\n",
    "ax2.plot(history.history['loss'], label='Training')\n",
    "ax2.plot(history.history['val_loss'], label='Validation')\n",
    "ax2.set_title('Model Loss')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bffe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "test_loss, test_accuracy, test_auc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test AUC: {test_auc:.4f}\")\n",
    "\n",
    "# Get predictions\n",
    "predictions = model.predict(X_test)\n",
    "predicted_labels = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = tf.math.confusion_matrix(y_test, predicted_labels)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "# Calculate additional metrics\n",
    "tn, fp, fn, tp = cm.numpy().ravel()\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# Save metrics\n",
    "metrics = {\n",
    "    'model': 'ecg_classifier',\n",
    "    'accuracy': float(test_accuracy),\n",
    "    'auc': float(test_auc),\n",
    "    'precision': float(precision),\n",
    "    'recall': float(recall),\n",
    "    'f1_score': float(f1),\n",
    "    'confusion_matrix': cm.numpy().tolist()\n",
    "}\n",
    "\n",
    "# Save to file\n",
    "with open('results/part_3/ecg_classifier_metrics.txt', 'w') as f:\n",
    "    f.write(f\"model: {metrics['model']}\\n\")\n",
    "    f.write(f\"accuracy: {metrics['accuracy']}\\n\")\n",
    "    f.write(f\"auc: {metrics['auc']}\\n\")\n",
    "    f.write(f\"precision: {metrics['precision']}\\n\")\n",
    "    f.write(f\"recall: {metrics['recall']}\\n\")\n",
    "    f.write(f\"f1_score: {metrics['f1_score']}\\n\")\n",
    "    f.write(f\"confusion_matrix: {metrics['confusion_matrix']}\\n\")\n",
    "    f.write(\"----\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665449b6",
   "metadata": {},
   "source": [
    "## Progress Checkpoints\n",
    "\n",
    "1. **Data Loading**:\n",
    "   - [ ] Successfully download MIT-BIH dataset\n",
    "   - [ ] Load and visualize ECG signals\n",
    "   - [ ] Verify signal shape and annotations\n",
    "\n",
    "2. **Preprocessing**:\n",
    "   - [ ] Normalize signals\n",
    "   - [ ] Extract beat windows\n",
    "   - [ ] Verify window shapes and labels\n",
    "\n",
    "3. **Model Implementation**:\n",
    "   - [ ] Create simple neural network\n",
    "   - [ ] Verify model architecture\n",
    "   - [ ] Test model output shape\n",
    "\n",
    "4. **Training**:\n",
    "   - [ ] Train model with callbacks\n",
    "   - [ ] Monitor training progress\n",
    "   - [ ] Save best model\n",
    "\n",
    "5. **Evaluation**:\n",
    "   - [ ] Calculate performance metrics\n",
    "   - [ ] Save metrics in correct format\n",
    "   - [ ] Visualize results\n",
    "\n",
    "## Common Issues and Solutions\n",
    "\n",
    "1. **Data Loading Issues**:\n",
    "   - Problem: MIT-BIH dataset not found\n",
    "   - Solution: Check internet connection and wfdb installation\n",
    "\n",
    "2. **Preprocessing Issues**:\n",
    "   - Problem: Signal normalization errors\n",
    "   - Solution: Check signal statistics and normalization method\n",
    "   - Problem: Window extraction errors\n",
    "   - Solution: Verify window size and padding\n",
    "\n",
    "3. **Model Issues**:\n",
    "   - Problem: Training instability\n",
    "   - Solution: Add batch normalization, reduce learning rate\n",
    "   - Problem: Overfitting\n",
    "   - Solution: Increase dropout, use data augmentation\n",
    "\n",
    "4. **Evaluation Issues**:\n",
    "   - Problem: Metrics format incorrect\n",
    "   - Solution: Follow the exact format specified\n",
    "   - Problem: Performance below threshold\n",
    "   - Solution: Adjust architecture, hyperparameters"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
